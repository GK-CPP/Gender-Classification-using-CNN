{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37366,
     "status": "ok",
     "timestamp": 1610051063157,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "grUXzfyEYP-H",
    "outputId": "663d747e-7038-4b1a-b9f1-6031fe662924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 883426,
     "status": "ok",
     "timestamp": 1610051979699,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "4XFWITL3Y83Z",
    "outputId": "99cca551-5ef9-4ba7-a62b-c3a70dd94154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name=\"/content/drive/MyDrive/Python file/Gender Classification/archive.zip\"\n",
    "\n",
    "with ZipFile(file_name,'r') as zip:\n",
    "  zip.extractall(\"/content/drive/MyDrive/Python file/Gender Classification\")\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1610056377820,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "01JYyF37Zfts"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,UpSampling2D,InputLayer,Reshape\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout,Activation,BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import LeakyReLU\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1610056388640,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "D1Oh8GDBaOjr"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "img_rows,img_cols = 96,96\n",
    "batch_size =16\n",
    "\n",
    "\n",
    "train_data_dir = \"/content/drive/MyDrive/Python file/Gender Classification/Training\"\n",
    "validation_data_dir = \"/content/drive/MyDrive/Python file/Gender Classification/Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1610056391871,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "BZRrZlrkahqh"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=30,\n",
    "                    shear_range=0.3,\n",
    "                    zoom_range=0.3,\n",
    "                    width_shift_range=0.4,\n",
    "                    height_shift_range=0.4,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2298,
     "status": "ok",
     "timestamp": 1610056395743,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "NVO_CLbLai4l",
    "outputId": "0b17a6ef-f23a-47d0-d031-8661633cf809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47009 images belonging to 2 classes.\n",
      "Found 11649 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    color_mode='grayscale',\n",
    "                    target_size=(img_rows,img_cols),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                    validation_data_dir,\n",
    "                    color_mode='grayscale',\n",
    "                    target_size=(img_rows,img_cols),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1610056403090,
     "user": {
      "displayName": "gk Palash",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggmz2C02-XF2_bB4ySQamUBCQPeFERYDcdKznPc0Q=s64",
      "userId": "08033763742240919797"
     },
     "user_tz": -360
    },
    "id": "ABB815cVamJ3",
    "outputId": "a8e2d9bb-ecb0-4d69-b41c-9c6f62924620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 8,674,626\n",
      "Trainable params: 8,671,746\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block-1\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsKoe0JVjCO9",
    "outputId": "3b3f73f1-2e7e-46d4-d36d-369019cf392e"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Python file/Gender Classification/Gender_Classification_model_2.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks = [checkpoint,earlystop,reduce_lr]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples = 47009\n",
    "nb_validation_samples = 11649\n",
    "epochs=100\n",
    "\n",
    "history=model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1nnTOS+E2k3Ox6qz6mv6u",
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
